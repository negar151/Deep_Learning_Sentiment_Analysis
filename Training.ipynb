{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA! TRAIN MODEL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from torch import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn.functional import pad\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"MirrorMask\" was a terribly disappointing film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I suppose you could say this film has a grain ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think that this was one of the most trite fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is terrible, it was so difficult to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Classic author C.S. Lewis once wrote an essay ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>Dogtown and Z-Boys&lt;br /&gt;&lt;br /&gt;Summary: Dogtown...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>Possibly the best John Travolta role ever. Sat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>The only way to truly understand and relate to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>I saw this at the San Francisco Independent Fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>This was truly a tense and dark episode. Excel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  1\n",
       "0     \"MirrorMask\" was a terribly disappointing film...  0\n",
       "1     I suppose you could say this film has a grain ...  0\n",
       "2     I think that this was one of the most trite fi...  0\n",
       "3     This movie is terrible, it was so difficult to...  0\n",
       "4     Classic author C.S. Lewis once wrote an essay ...  0\n",
       "...                                                 ... ..\n",
       "7495  Dogtown and Z-Boys<br /><br />Summary: Dogtown...  1\n",
       "7496  Possibly the best John Travolta role ever. Sat...  1\n",
       "7497  The only way to truly understand and relate to...  1\n",
       "7498  I saw this at the San Francisco Independent Fi...  1\n",
       "7499  This was truly a tense and dark episode. Excel...  1\n",
       "\n",
       "[7500 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data = pd.read_csv('data/imdb_reviews/train.csv', header=None)\n",
    "raw_val_data = pd.read_csv('data/imdb_reviews/val.csv', header=None)\n",
    "raw_test_data = pd.read_csv('data/imdb_reviews/test.csv', header=None)\n",
    "raw_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_whitespace(df: pd.DataFrame):\n",
    "    stripped_df = df.apply(lambda x : x.str.strip() if x.dtype == 'object' else x)\n",
    "    return stripped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = strip_whitespace(raw_train_data)\n",
    "raw_val_data = strip_whitespace(raw_val_data)\n",
    "raw_test_data = strip_whitespace(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file_path = 'data/pretrained_models/GoogleNews-vectors-negative300.bin'\n",
    "word2vec = KeyedVectors.\\\n",
    "            load_word2vec_format(embedding_file_path, binary=True)\n",
    "word2vec['<UNK>'] = np.zeros(300)\n",
    "word2vec['<PAD>'] = np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_int = {}\n",
    "int_to_word = {}\n",
    "for i, x in enumerate(word2vec.vocab):\n",
    "    word_to_int[x] = i\n",
    "    int_to_word[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_word_to_int(s: str):\n",
    "    if s in word_to_int:\n",
    "        return word_to_int[s]\n",
    "    else:\n",
    "        return word_to_int['<UNK>']\n",
    "\n",
    "def map_int_to_word(n: int):\n",
    "    if n in int_to_word:\n",
    "        return int_to_word[n]\n",
    "    else:\n",
    "        return int_to_word[len(int_to_word) - 2]\n",
    "    \n",
    "def str_to_int_array(s: str):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return np.array([map_word_to_int(x) for x in tokenizer.tokenize(s)])\n",
    "\n",
    "def int_array_to_str(a: np.array):\n",
    "    return reduce(lambda x, y : '{} {}'.format(x, map_int_to_word(y)), a, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, features: list, targets: list):\n",
    "        super(MovieDataset, self).__init__()\n",
    "        \n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx]), torch.tensor(self.targets[idx], \n",
    "                                                              dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_raw_data(df: pd.DataFrame):\n",
    "    \n",
    "    features = [str_to_int_array(x) for x in df.iloc[:, 0]]\n",
    "    targets = df.iloc[:, 1].to_numpy().tolist()\n",
    "    \n",
    "    return features, targets\n",
    "\n",
    "def generate_dataset(df: pd.DataFrame):\n",
    "    features, targets = refine_raw_data(df)\n",
    "    \n",
    "    return MovieDataset(features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = generate_dataset(raw_train_data)\n",
    "val_dataset = generate_dataset(raw_val_data)\n",
    "test_dataset = generate_dataset(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch(batch):\n",
    "    data = [x[0] for x in batch]\n",
    "    L = len(max(data, key=len))\n",
    "    \n",
    "    data = torch.stack([pad(x, (0, (L- len(x)))) for x in data])\n",
    "    targets = torch.tensor([x[1] for x in batch]).squeeze(0)\n",
    "    \n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=pad_batch,\n",
    "                          shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, collate_fn=pad_batch, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, collate_fn=pad_batch,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysisCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, filter_sizes, num_filters, hidden_dim, lr):\n",
    "        super(SentimentAnalysisCNN, self).__init__()\n",
    "        \n",
    "        ### Hyperparameters ###\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.num_filters = num_filters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lr = lr\n",
    "        #######################\n",
    "        \n",
    "        self.model_name = reduce(lambda x, y : x + str(y), self.filter_sizes, '') + '_' \\\n",
    "                            + str(self.num_filters) + '_' + str(self.hidden_dim) + '_' \\\n",
    "                            + str(lr)\n",
    "        \n",
    "        # Embed the input\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(word2vec.vectors))\n",
    "        \n",
    "        # Time to convoulte!\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, \n",
    "                                              self.num_filters, \n",
    "                                              kernel_size=(h, 300))\n",
    "                                    for h in self.filter_sizes])\n",
    "        \n",
    "        # Feed forward\n",
    "        fc_input = self.num_filters * len(self.filter_sizes)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "                                        nn.Linear(fc_input, self.hidden_dim),\n",
    "                                        nn.CELU(),\n",
    "                                        nn.Dropout(0.4),\n",
    "                                        nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "                                        nn.CELU(),\n",
    "                                        nn.Dropout(0.4),\n",
    "                                        nn.Linear(hidden_dim, 1),\n",
    "                                        nn.Sigmoid()\n",
    "                                       )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        conv_outputs = [self.convolute_and_pool(x, c) for c in self.convs]\n",
    "        x = torch.cat(conv_outputs, 1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "    def convolute_and_pool(self, x, conv):\n",
    "        x = torch.relu(conv(x))\n",
    "        x = x.squeeze(3)\n",
    "        return torch.max_pool1d(x, x.size(2)).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_metrics(model, validation=False):\n",
    "    \n",
    "    gpu_is_available = False\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        gpu_is_available = True\n",
    "    \n",
    "    if validation:\n",
    "        eval_loader = val_loader\n",
    "    else:\n",
    "        eval_loader = test_loader\n",
    "    \n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for data, targets in eval_loader:\n",
    "        if gpu_is_available:\n",
    "            data, targets = data.cuda(), targets.cuda()\n",
    "        predictions = model.forward(data)\n",
    "        predictions = torch.round(predictions.reshape(-1))\n",
    "        results = Counter(((2 * targets) - predictions).tolist())\n",
    "        true_positives += results[float(1)]\n",
    "        true_negatives += results[float(0)]\n",
    "        false_positives += results[float(-1)]\n",
    "        false_negatives += results[float(2)]\n",
    "    accuracy = (true_positives + true_negatives) / (true_positives\n",
    "                                                    + true_negatives\n",
    "                                                    + false_positives\n",
    "                                                    + false_negatives)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "    return (accuracy, precision, recall, f1)\n",
    "\n",
    "def evaluate_model(model, validation=False):\n",
    "    \n",
    "    gpu_is_available = False\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        gpu_is_available = True\n",
    "    \n",
    "    if validation:\n",
    "        eval_loader = val_loader\n",
    "    else:\n",
    "        eval_loader = test_loader\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    accuracy = 0.\n",
    "    num_correct = 0\n",
    "    for features, targets in eval_loader:\n",
    "        if gpu_is_available:\n",
    "            features, targets = features.cuda(), targets.cuda()\n",
    "\n",
    "        output = model.forward(features)\n",
    "        equality_results = torch.round(output.reshape(-1)) == targets\n",
    "        num_correct += sum(equality_results.tolist())\n",
    "    accuracy = (num_correct / len(val_loader.dataset)) * 100.0\n",
    "    return accuracy\n",
    "\n",
    "def train_model(model, logger, epochs=5, lr=1e-4):\n",
    "    \n",
    "    gpu_is_available = False\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        gpu_is_available = True\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.\n",
    "        for features, targets in train_loader:\n",
    "            \n",
    "            if gpu_is_available:\n",
    "                features, targets = features.cuda(), targets.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(features)\n",
    "            loss = criterion(output.squeeze(), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        accuracy = evaluate_model(model, validation=True)\n",
    "        \n",
    "        logger.add_scalar('Loss/{}'.format(model.model_name + str(lr)), running_loss, e)\n",
    "        logger.add_scalar('Accuracy/{}'.format(model.model_name + str(lr)), accuracy, e)\n",
    "        \n",
    "        print('Epoch: {}\\t Train Loss: {:.2f}\\tValidation Accuracy: {:.2f}%'\\\n",
    "              .format(e,\n",
    "                      running_loss,\n",
    "                      accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search... probably don't run this ever again... took like 3 days to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrs = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "# hidden_dims = [32, 256, 1025, 2048, 4096]\n",
    "# filter_sizes = [[2, 3, 4], [3, 4, 5], [4, 5, 6]]\n",
    "# num_filters = [32, 64, 128, 256, 512]\n",
    "\n",
    "# logger = SummaryWriter('hyperparameter_search')\n",
    "\n",
    "# for i, lr in enumerate(lrs, 2):\n",
    "#     for h in hidden_dims:\n",
    "#         for f_s in filter_sizes:\n",
    "#             for n_f in num_filters:\n",
    "#                 model = None\n",
    "#                 gc.collect()\n",
    "#                 torch.cuda.empty_cache()\n",
    "#                 model = SentimentAnalysisCNN(f_s, n_f, h, i)\n",
    "#                 train_model(model, logger, epochs=20, lr=lr)\n",
    "\n",
    "# logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = evaluate_model_metrics(model)\n",
    "# print('Accuracy: {:.4f}\\nPrecision: {:.4f}\\nRecall: {:.4f}\\nF1 Score: {:.4f}'\\\n",
    "#      .format(*metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t Train Loss: 475.71\tValidation Accuracy: 88.71%\n",
      "Epoch: 2\t Train Loss: 254.81\tValidation Accuracy: 89.85%\n",
      "Epoch: 3\t Train Loss: 133.34\tValidation Accuracy: 90.81%\n",
      "Epoch: 4\t Train Loss: 37.00\tValidation Accuracy: 91.27%\n",
      "Epoch: 5\t Train Loss: 8.08\tValidation Accuracy: 91.57%\n",
      "Epoch: 6\t Train Loss: 11.92\tValidation Accuracy: 88.63%\n",
      "Epoch: 7\t Train Loss: 16.98\tValidation Accuracy: 91.45%\n",
      "Epoch: 8\t Train Loss: 10.51\tValidation Accuracy: 91.08%\n",
      "Epoch: 9\t Train Loss: 2.96\tValidation Accuracy: 91.16%\n"
     ]
    }
   ],
   "source": [
    "logger = SummaryWriter('further_testing')\n",
    "\n",
    "model = SentimentAnalysisCNN([2, 4, 5, 6], 1400, 32, 0.0001)\n",
    "train_model(model, logger, epochs=20, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_model_metrics(model)\n",
    "print('Accuracy: {:.4f}\\nPrecision: {:.4f}\\nRecall: {:.4f}\\nF1 Score: {:.4f}'\\\n",
    "     .format(*metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
